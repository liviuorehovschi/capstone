{% extends "base.html" %}

{% block title %}Technical Details - Lung Histopathology AI Classifier{% endblock %}

{% block extra_css %}
<style>
    .tech-section {
        margin-bottom: 2rem;
        background: var(--dark-gray);
        border: 1px solid var(--glass-border);
        border-radius: 8px;
        padding: 2rem;
        backdrop-filter: blur(8px);
    }

    .tech-section h2 {
        color: var(--light-gray);
        margin-bottom: 1.5rem;
        font-size: 1.6rem;
        text-transform: uppercase;
        letter-spacing: 2px;
        border-bottom: 2px solid var(--medium-gray);
        padding-bottom: 0.5rem;
    }

    .tech-section h3 {
        color: var(--light-gray);
        margin: 1.5rem 0 1rem 0;
        font-size: 1.3rem;
    }

    .tech-details {
        background: var(--darker-gray);
        padding: 1.5rem;
        border-radius: 5px;
        margin-bottom: 1.5rem;
    }

    .architecture-diagram {
        width: 100%;
        max-width: 800px;
        margin: 2rem auto;
        display: block;
    }

    .metric-grid {
        display: grid;
        grid-template-columns: repeat(2, 1fr);
        gap: 1.5rem;
        margin: 1.5rem 0;
    }

    .metric-card {
        background: var(--dark-gray);
        border: 1px solid var(--glass-border);
        padding: 1.5rem;
        border-radius: 5px;
        box-shadow: 0 2px 8px var(--shadow);
        text-align: center;
    }

    .metric-card h3 {
        color: var(--light-gray);
    }

    .metric-card p {
        color: var(--medium-gray);
    }

    .code-block {
        background: var(--darker-gray);
        color: var(--accent-gray);
        padding: 1.5rem;
        border-radius: 5px;
        overflow-x: auto;
        margin: 1rem 0;
    }
</style>
{% endblock %}

{% block content %}
<div class="tech-section">
    <h2>Model Architecture</h2>
    <div class="tech-details">
        <h3>CNN Architecture Overview</h3>
        <p>This project leverages the EfficientNet-B0 architecture, a convolutional neural network known for achieving high performance with fewer parameters. EfficientNet-B0 was selected due to its balance of speed, accuracy, and scalability, which is crucial for real-time inference in a web-based diagnostic tool.</p>

        <p>The model utilizes transfer learning from ImageNet weights, with the base layers frozen during early training. A custom classification head was added to the model, composed of global average pooling, dropout regularization, and fully connected layers to classify three categories: benign, adenocarcinoma, and squamous cell carcinoma.</p>

        <h3>Key Components</h3>
        <ul>
            <li><strong>Input Layer:</strong> Preprocessed 224x224 RGB images</li>
            <li><strong>Feature Extraction:</strong> Pretrained EfficientNet-B0 base</li>
            <li><strong>Dropout Layers:</strong> 0.2 and 0.5 dropout rates to reduce overfitting</li>
            <li><strong>Classification Head:</strong> Dense → Dropout → Dense with softmax output</li>
            <li><strong>Activation:</strong> ReLU in intermediate layers, softmax at output</li>
            <li><strong>Loss Function:</strong> Categorical crossentropy</li>
            <li><strong>Optimizer:</strong> Adam with learning rate warm-up and decay</li>
        </ul>
    </div>
</div>

<div class="tech-section">
    <h2>Development Environment</h2>
    <div class="tech-details">
        <h3>Hardware Configuration</h3>
        <ul>
            <li>Training: Google Colab Pro with NVIDIA T4 and A100 GPUs</li>
            <li>RAM: 16 GB for model development and training sessions</li>
            <li>Testing and Deployment: Local CPU and browser for performance validation</li>
        </ul>

        <h3>Software Stack</h3>
        <div class="code-block">
<pre>
Python 3.8
TensorFlow 2.7
Flask 2.0
OpenCV 4.5
NumPy 1.21
Pandas 1.3
Matplotlib 3.4
Pillow 8.4
Gunicorn (for deployment)
</pre>
        </div>

        <h3>Deployment Notes</h3>
        <p>The final model and web interface are bundled into a lightweight Flask application. Grad-CAM and saliency visualizations are computed dynamically using in-memory buffers to avoid disk writes — an important consideration for deployment in restricted environments like Heroku or Docker containers.</p>
    </div>
</div>

<div class="tech-section">
    <h2>Model Performance</h2>
    <div class="tech-details">
        <p>The final model was evaluated on a hold-out test set containing a balanced distribution of real histopathological images from both LC25000 and LungHist7000 datasets. Metrics were calculated using scikit-learn’s classification tools. Data augmentation included horizontal/vertical flips, rotation, and color jittering.</p>

        <div class="metric-grid">
            <div class="metric-card">
                <h3>Accuracy</h3>
                <p>98.2%</p>
            </div>
            <div class="metric-card">
                <h3>Precision</h3>
                <p>97.9%</p>
            </div>
            <div class="metric-card">
                <h3>Recall</h3>
                <p>97.6%</p>
            </div>
            <div class="metric-card">
                <h3>F1 Score</h3>
                <p>97.7%</p>
            </div>
        </div>

        <h3>Class-wise Accuracy</h3>
        <ul>
            <li><strong>Benign:</strong> 99.1%</li>
            <li><strong>Adenocarcinoma:</strong> 97.3%</li>
            <li><strong>Squamous Cell Carcinoma:</strong> 98.0%</li>
        </ul>

        <h3>Explainability Features</h3>
        <p>The diagnostic interface includes interactive support for saliency maps and Grad-CAM overlays. These help users visually verify which areas of the tissue image contributed to the AI's decision, improving trust and interpretability — a key priority in clinical settings.</p>
    </div>
</div>
{% endblock %}
